@article{li2023towards,
  title       = {Towards Knowledge-driven Autonomous Driving},
  author      = {Xin Li and Yeqi Bai and Pinlong Cai and Licheng Wen and Daocheng Fu and Bo Zhang and Xuemeng Yang and Xinyu Cai and Tao Ma and Jianfei Guo and Xing Gao and Min Dou and Yikang Li and Botian Shi and Yong Liu and Liang He and Yu Qiao},
  abstract    = {This paper explores the emerging knowledge-driven autonomous driving technologies. Our investigation highlights the limitations of current autonomous driving systems, in particular their sensitivity to data bias, difficulty in handling long-tail scenarios, and lack of interpretability. Conversely, knowledge-driven methods with the abilities of cognition, generalization and life-long learning emerge as a promising way to overcome these challenges. This paper delves into the essence of knowledge-driven autonomous driving and examines its core components: dataset \& benchmark, environment, and driver agent. By leveraging large language models, world models, neural rendering, and other advanced artificial intelligence techniques, these components collectively contribute to a more holistic, adaptive, and intelligent autonomous driving system. The paper systematically organizes and reviews previous research efforts in this area, and provides insights and guidance for future research and practical applications of autonomous driving. We will continually share the latest updates on cutting-edge developments in knowledge-driven autonomous driving along with the relevant valuable open-source resources at: https://github.com/PJLab-ADG/awesome-knowledge-driven-AD },
  journal     = {arXiv preprint arXiv:2312.04316},
  year        = {2023},
  arxiv       = {2312.04316},
  bibtex_show = {true},
  preview     = {survey.png},
  selected    = {false}
}



@article{yang2024drivearena,
  title={DriveArena: A Closed-loop Generative Simulation Platform for Autonomous Driving}, 
  author={Xuemeng Yang* and Licheng Wen* and Yukai Ma* and Jianbiao Mei* and Xin Li* and Tiantian Wei* and Wenjie Lei and Daocheng Fu and Pinlong Cai and Min Dou and Botian Shi and Liang He and Yong Liu and Yu Qiao},
  journal={arXiv preprint arXiv:2408.00415},
  year={2024},
  abstract    = {This paper presetns DriveArena, the first high-fidelity closed-loop simulation system designed for driving agents navigating in real scenarios. DriveArena features a flexible, modular architecture, allowing for the seamless interchange of its core components: Traffic Manager, a traffic simulator capable of generating realistic traf- fic flow on any worldwide street map, and World Dreamer, a high-fidelity conditional generative model with infinite autoregression. This powerful synergy empowers any driving agent capable of processing real-world images to navigate in DriveArena simulated environment. The agent perceives its surroundings through images generated by World Dreamer and output trajectories; then these trajectories are fed into Traffic Manager, achieving realistic interactions with other vehicles and producing a new scene lay- out. Finally, the latest scene layout is relayed back into World Dreamer, perpetuating the simulation cycle. This iterative process fosters closed-loop exploration within a highly realistic environment, providing a valuable platform for developing and evaluating driving agents across diverse and challenging scenarios. DriveArena signifies a substantial leap forward in leveraging generative image data for the driving simulatior, opening insights for closed-loop autonomous driving.},
  abbr        = {Preprint},
  arxiv       = {2408.00415},
  bibtex_show = {true},
  preview     = {drivearena.png},
  code        = {https://github.com/pjlab-adg/DriveArena},
  demo        = {https://pjlab-adg.github.io/DriveArena/}
}

@article{mei2024continuously,
  title       = {Continuously Learning, Adapting, and Improving: A Dual-Process Approach to Autonomous Driving},
  author      = {Mei*, Jianbiao and Ma*, Yukai and Yang, Xuemeng and Wen, Licheng and Cai, Xinyu and Li, Xin and Fu, Daocheng and Zhang, Bo and Cai, Pinlong and Dou, Min and others},
  journal     = {Advances in Neural Information Processing Systems (NeurIPS)},
  year        = {2024},
  abstract    = {Autonomous driving has advanced significantly due to sensors, machine learning, and artificial intelligence improvements. However, prevailing methods struggle with intricate scenarios and causal relationships, hindering adaptability and interpretability in varied environments. To address the above problems, we introduce LeapAD, a novel paradigm for autonomous driving inspired by the human cognitive process. Specifically, LeapAD emulates human attention by selecting critical objects relevant to driving decisions, simplifying environmental interpretation, and mitigating decision-making complexities. Additionally, LeapAD incorporates an innovative dual-process decision-making module, which consists of an Analytic Process (System-II) for thorough analysis and reasoning, along with a Heuristic Process (System-I) for swift and empirical processing. The Analytic Process leverages its logical reasoning to accumulate linguistic driving experience, which is then transferred to the Heuristic Process by supervised fine-tuning. Through reflection mechanisms and a growing memory bank, LeapAD continuously improves itself from past mistakes in a closed-loop environment. Closed-loop testing in CARLA shows that LeapAD outperforms all methods relying solely on camera input, requiring 1-2 orders of magnitude less labeled data. Experiments also demonstrate that as the memory bank expands, the Heuristic Process with only 1.8B parameters can inherit the knowledge from a GPT-4 powered Analytic Process and achieve continuous performance improvement.},
  abbr        = {NeurIPS},
  arxiv       = {2405.15324},
  bibtex_show = {true},
  preview     = {leapad.png},
  code        = {https://github.com/pjlab-adg/leapad},
  demo        = {https://leapad-2024.github.io/LeapAD/}
}

@inproceedings{fu2024limsim,
  title        = {LimSim++: A Closed-Loop Platform for Deploying Multimodal LLMs in Autonomous Driving},
  author       = {Daocheng Fu* and Wenjie Lei* and Licheng Wen and Pinlong Cai and Song Mao and Min Dou and Botian Shi and Yu Qiao},
  booktitle    = {2024 IEEE Intelligent Vehicles Symposium (IV)},
  year         = {2024},
  organization = {IEEE},
  abstract     = {The emergence of Multimodal Large Language Models ((M)LLMs) has ushered in new avenues in artificial intelligence, particularly for autonomous driving by offering enhanced understanding and reasoning capabilities. This paper introduces LimSim++, an extended version of LimSim designed for the application of (M)LLMs in autonomous driving. Acknowledging the limitations of existing simulation platforms, LimSim++ addresses the need for a long-term closed-loop infrastructure supporting continuous learning and improved generalization in autonomous driving. The platform offers extended-duration, multi-scenario simulations, providing crucial information for (M)LLM-driven vehicles. Users can engage in prompt engineering, model evaluation, and framework enhancement, making LimSim++ a versatile tool for research and practice. This paper additionally introduces a baseline (M)LLM-driven framework, systematically validated through quantitative experiments across diverse scenarios. },
  abbr         = {IV},
  arxiv        = {2402.01246},
  bibtex_show  = {true},
  code         = {https://github.com/PJLab-ADG/LimSim/tree/LimSim_plus},
  demo         = {https://pjlab-adg.github.io/limsim_plus/}
}

@inproceedings{wen2023dilu,
  title        = {DiLu: A Knowledge-Driven Approach to Autonomous Driving with Large Language Models},
  author       = {Licheng Wen* and Daocheng Fu* and Xin Li* and Xinyu Cai and Tao Ma and Pinlong Cai and Min Dou and Botian Shi and Liang He and Yu Qiao},
  booktitle    = {The Eleventh International Conference on Learning Representations (ICLR)},
  year         = {2024},
  abstract     = {Recent advancements in autonomous driving have relied on data-driven approaches, which are widely adopted but face challenges including dataset bias, overfitting, and uninterpretability. Drawing inspiration from the knowledge-driven nature of human driving, we explore the question of how to instill similar capabilities into autonomous driving systems and summarize a paradigm that integrates an interactive environment, a driver agent, as well as a memory component to address this question. Leveraging large language models with emergent abilities, we propose the DiLu framework, which combines a Reasoning and a Reflection module to enable the system to perform decision-making based on common-sense knowledge and evolve continuously. Extensive experiments prove DiLu's capability to accumulate experience and demonstrate a significant advantage in generalization ability over reinforcement learning-based methods. Moreover, DiLu is able to directly acquire experiences from real-world datasets which highlights its potential to be deployed on practical autonomous driving systems. To the best of our knowledge, we are the first to instill knowledge-driven capability into autonomous driving systems from the perspective of how humans drive.},
  abbr         = {ICLR},
  arxiv        = {2309.16292},
  bibtex_show  = {true},
  code         = {https://github.com/PJLab-ADG/DiLu},
  demo         = {https://pjlab-adg.github.io/DiLu/},
  selected     = {true}
}


@inproceedings{wen2024road,
  title       = {On the Road with GPT-4V(ision): Early Explorations of Visual-Language Model on Autonomous Driving},
  author      = {Licheng Wen* and Xuemeng Yang* and Daocheng Fu* and Xiaofeng Wang* and Pinlong Cai and Xin Li and Tao Ma and Yingxuan Li and Linran Xu and Dengke Shang and Zheng Zhu and Shaoyan Sun and Yeqi Bai and Xinyu Cai and Min Dou and Shuanglu Hu and Botian Shi},
  booktitle={ICLR 2024 Workshop on Large Language Model (LLM) Agents},
  year={2024},
  abstract    = {The development of autonomous driving technology depends on merging perception, decision, and control systems. Traditional strategies have struggled to understand complex driving environments and other road users' intent. This bottleneck, especially in constructing common sense reasoning and nuanced scene understanding, affects the safe and reliable operations of autonomous vehicles. The introduction of Visual Language Models (VLM) opens up possibilities for fully autonomous driving. This report evaluates the potential of GPT-4V(ision), the latest state-of-the-art VLM, as an autonomous driving agent. The evaluation primarily assesses the model's ultimate ability to act as a driving agent under varying conditions, while also considering its capacity to understand driving scenes and make decisions. Findings show that GPT-4V outperforms existing systems in scene understanding and causal reasoning. It has the potential in handling unexpected scenarios, understanding intentions, and making informed decisions. However, limitations remain in direction determination, traffic light recognition, vision grounding, and spatial reasoning tasks, highlighting the need for further research. },
  abbr        = {Preprint},
  preview     = {on_the_road.png},
  arxiv       = {2311.05332},
  bibtex_show = {true},
  code        = {https://github.com/PJLab-ADG/GPT4V-AD-Exploration},
  selected    = {true}
}

@article{wen2023trafficmcts,
  title        = {TrafficMCTS: A Closed-Loop Traffic Flow Generation Framework with Group-Based Monte Carlo Tree Search},
  author       = {Licheng Wen* and Ze Fu* and Pinlong Cai and Daocheng Fu and Song Mao and Botian Shi},
  year         = {2023},
  journal      = {arXiv preprint arXiv:2308.12797},
  primaryclass = {cs.RO},
  abstract     = {Digital twins for intelligent transportation systems are currently attracting great interests, in which generating realistic, diverse, and human-like traffic flow in simulations is a formidable challenge. Current approaches often hinge on predefined driver models, objective optimization, or reliance on pre-recorded driving datasets, imposing limitations on their scalability, versatility, and adaptability. In this paper, we introduce TrafficMCTS, an innovative framework that harnesses the synergy of groupbased Monte Carlo tree search (MCTS) and Social Value Orientation (SVO) to engender a multifaceted traffic flow replete with varying driving styles and cooperative tendencies. Anchored by a closed-loop architecture, our framework enables vehicles to dynamically adapt to their environment in real time, and ensure feasible collision-free trajectories. Through comprehensive comparisons with state-of-the-art methods, we illuminate the advantages of our approach in terms of computational efficiency, planning success rate, intent completion time, and diversity metrics. Besides, we simulate highway and roundabout scenarios to illustrate the effectiveness of the proposed framework and highlight its ability to induce diverse social behaviors within the traffic flow. Finally, we validate the scalability of TrafficMCTS by showcasing its prowess in simultaneously mass vehicles within a sprawling road network, cultivating a landscape of traffic flow that mirrors the intricacies of human behavior.},
  abbr         = {Preprint},
  arxiv        = {2308.12797},
  bibtex_show  = {true},
  selected     = {false}
}


@article{fu2023drive,
  title       = {Drive Like a Human: Rethinking Autonomous Driving with Large Language Models},
  author      = {Daocheng Fu* and Xin Li* and Licheng Wen* and Min Dou and Pinlong Cai and Botian Shi and Yu Qiao},
  journal     = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) Workshops},
  year        = {2024},
  abstract    = {In this paper, we explore the potential of using a large language model (LLM) to understand the driving environment in a human-like manner and analyze its ability to reason, interpret, and memorize when facing complex scenarios. We argue that traditional optimization-based and modular autonomous driving (AD) systems face inherent performance limitations when dealing with long-tail corner cases. To address this problem, we propose that an ideal AD system should drive like a human, accumulating experience through continuous driving and using common sense to solve problems. To achieve this goal, we identify three key abilities necessary for an AD system: reasoning, interpretation, and memorization. We demonstrate the feasibility of employing an LLM in driving scenarios by building a closed-loop system to showcase its comprehension and environment-interaction abilities. Our extensive experiments show that the LLM exhibits the impressive ability to reason and solve long-tailed cases, providing valuable insights for the development of human-like autonomous driving.},
  abbr        = {WS@WACV},
  arxiv       = {2307.07162},
  code        = {https://github.com/PJLab-ADG/DriveLikeAHuman},
  bibtex_show = {true},
  selected    = {false}
}


@article{zang2024,
  title       = {How drivers perform under different scenarios: Ability-related driving style extraction for large-scale dataset},
  journal     = {Accident Analysis & Prevention},
  volume      = {196},
  pages       = {107445},
  year        = {2024},
  issn        = {0001-4575},
  doi         = {https://doi.org/10.1016/j.aap.2023.107445},
  url         = {https://www.sciencedirect.com/science/article/pii/S000145752300492X},
  author      = {Yingbang Zang and Licheng Wen and Pinlong Cai and Daocheng Fu and Song Mao and Botian Shi and Yikang Li and Guangquan Lu},
  keywords    = {Driving style, Traffic scenario, Gaussian mixture model, Jensen–Shannon divergence, Large-scale dataset},
  abstract    = {The extraction and analysis of driving style are essential for a comprehensive understanding of human driving behaviours. Most existing studies rely on subjective questionnaires and specific experiments, posing challenges in accurately capturing authentic characteristics of group drivers in naturalistic driving scenarios. As scenario-oriented naturalistic driving data collected by advanced sensors becomes increasingly available, the application of data-driven methods allows for a exhaustive analysis of driving styles across multiple drivers. Following a theoretical differentiation of driving ability, driving performance, and driving style with essential clarifications, this paper proposes a quantitative determination method grounded in large-scale naturalistic driving data. Initially, this paper defines and derives driving ability and driving performance through trajectory optimisation modelling considering various cost indicators. Subsequently, this paper proposes an objective driving style extraction method grounded in the Gaussian mixture model. In the experimental phase, this study employs the proposed framework to extract both driving abilities and performances from the Waymo motion dataset, subsequently determining driving styles. This determination is accomplished through the establishment of quantifiable statistical distributions designed to mirror data characteristics. Furthermore, the paper investigates the distinctions between driving styles in different scenarios, utilising the Jensen–Shannon divergence and the Wilcoxon rank-sum test. The empirical findings substantiate correlations between driving styles and specific scenarios, encompassing both congestion and non-congestion as well as intersection and non-intersection scenarios.},
  abbr        = {AAP},
  bibtex_show = {true}
}

@thesis{2022wenthesis,
  title       = {Research and Application of Heterogeneous Multi-Agent Path Planning Method with Kinematic Constraints},
  author      = {Licheng Wen},
  editor      = {Yong Liu},
  abstract    = {In recent years, with the widespread application of multi-agent systems in robotics and artificial intelligence, the issue of multi-agent path planning has gained increasing attention from scholars. Efficiently generating obstacle-avoidance paths for agents within a system while ensuring collision-free interactions has become a crucial task in multi-agent collaboration. Additionally, as the level of intelligence in agent control systems continues to advance, the corresponding network security threats have also increased. Ensuring the secure and stable operation of such systems has become a significant challenge to address. This thesis presents a comprehensive multi-agent path planning solution applicable to real industrial scenarios. The proposed solution can generate paths for a heterogeneous multi-agent system within a continuous workspace that adhere to the agents' kinematic models. It also robustly handles exceptional situations that may arise during the execution of planned paths. The main contributions of this thesis are as follows: 1. A multi-agent path planning approach is proposed specifically for Ackermann models. This solver employs a hierarchical search framework: in the upper-level search, the concept of a vehicle body constraint tree is introduced, which checks for vehicle body conflicts between paths in the planning solution without considering specific kinematic constraints; in the lower-level search, a spatiotemporal hybrid A* algorithm is introduced for single-agent path planning. This method can generate safe obstacle-avoidance paths for a large number of Ackermann motion model agents within a continuous workspace, significantly outperforming baseline algorithms. 2. An online path planning method suitable for heterogeneous multi-agent systems is introduced. Building upon the previous method, this approach generalizes the lower-level single-agent path planning algorithm, extending the applicability to heterogeneous multi-agent systems with varying sizes, shapes, and kinematic models. Additionally, the rolling time-domain collision resolution algorithm is integrated into the conflict search framework, addressing real-world industrial application scenarios with task flows and enhancing the efficiency of the planning system. 3. A post-processing framework for multi-agent path planning based on action dependency graphs is proposed. Leveraging the planning results generated by the aforementioned solver, this framework analyzes the priority relationships of agent movements and requires minimal communication between agents and the planner to actively detect anomalous behavior within the system. Through this post-processing framework, the thesis ensures the safe and robust execution of planning solutions for multi-agent systems over extended periods.},
  year        = 2022,
  school      = {Zhejiang University},
  keywords    = {multi-agent systems; path planning; mobile robots; industrial control system security},
  abbr        = {Thesis},
  bibtex_show = {true},
  html        = {https://doi.org/10.27461/d.cnki.gzjdx.2022.001837},
  pdf         = {master_thesis.pdf}
}


@inproceedings{wen2023limsim,
  title       = {LimSim: A Long-term Interactive Multi-scenario Traffic Simulator},
  author      = {Licheng Wen* and Daocheng Fu* and Song Mao and Pinlong Cai and Min Dou and Yikang Li},
  year        = {2023},
  booktitle   = {2023 IEEE 26th International Conference on Intelligent Transportation Systems (ITSC)},
  abstract    = {With the growing popularity of digital twin and autonomous driving in transportation, the demand for simulation systems capable of generating high-fidelity and reliable scenarios is increasing. Existing simulation systems suffer from a lack of support for different types of scenarios, and the vehicle models used in these systems are too simplistic. Thus, such systems fail to represent driving styles and multi-vehicle interactions, and struggle to handle corner cases in the dataset. In this paper, we propose LimSim, the Long-term Interactive Multi-scenario traffic Simulator, which aims to provide a long-term continuous simulation capability under the urban road network. LimSim can simulate fine-grained dynamic scenarios and focus on the diverse interactions between multiple vehicles in the traffic flow. This paper provides a detailed introduction to the framework and features of the LimSim, and demonstrates its performance through case studies and experiments. LimSim is now open source on GitHub.},
  abbr        = {ITSC},
  arxiv       = {2307.06648},
  code        = {https://github.com/PJLab-ADG/LimSim},
  video       = {https://www.youtube.com/playlist?list=PLNeNtm096CAyYD1JJnkQ4gMaoFSdFLn2y},
  bibtex_show = {true},
  selected    = {true}
}

@article{tong2023human,
  title       = {Human-like Decision-making at Unsignalized Intersection using Social Value Orientation},
  author      = {Tong, Yan and Wen, Licheng and Cai, Pinlong and Fu, Daocheng and Mao, Song and Li, Yikang},
  journal     = {IEEE Intelligent Transportation Systems Magazine},
  pages       = {2-16},
  year        = {2023},
  doi         = {10.1109/MITS.2023.3342308},
  abstract    = {With the commercial application of automated vehicles (AVs), the sharing of roads between AVs and human-driven vehicles (HVs) becomes a common occurrence in the future. While research has focused on improving the safety and reliability of autonomous driving, it's also crucial to consider collaboration between AVs and HVs. Human-like interaction is a required capability for AVs, especially at common unsignalized intersections, as human drivers of HVs expect to maintain their driving habits for inter-vehicle interactions. This paper uses the social value orientation (SVO) in the decision-making of vehicles to describe the social interaction among multiple vehicles. Specifically, we define the quantitative calculation of the conflict-involved SVO at unsignalized intersections to enhance decision-making based on the reinforcement learning method. We use naturalistic driving scenarios with highly interactive motions for performance evaluation of the proposed method. Experimental results show that SVO is more effective in characterizing inter-vehicle interactions than conventional motion state parameters like velocity, and the proposed method can accurately reproduce naturalistic driving trajectories compared to behavior cloning.},
  abbr        = {IEEE ITSM},
  arxiv       = {2306.17456},
  bibtex_show = {true},
  selected    = {false}
}

@inproceedings{10.5555/3545946.3599005,
  author      = {Wen, Licheng and Cai, Pinlong and Fu, Daocheng and Mao, Song and Li, Yikang},
  title       = {Bringing Diversity to Autonomous Vehicles: An Interpretable Multi-Vehicle Decision-Making and Planning Framework},
  year        = {2023},
  isbn        = {9781450394321},
  publisher   = {International Foundation for Autonomous Agents and Multiagent Systems},
  address     = {Richland, SC},
  abstract    = {With the development of autonomous driving, it is becoming increasingly common for autonomous vehicles (AVs) and human-driven vehicles (HVs) to share the same roads. We propose a hierarchical multi-vehicle decision-making and planning framework with several advantages. The framework makes decisions jointly for all vehicles within the traffic flow and reacts promptly to the dynamic environment through a high-frequency planning module. The decision module produces interpretable action sequences that can explicitly communicate self-intentions to the surrounding HVs. We also present the cooperation factor and the trajectory weight set, which bring diversity to autonomous vehicles in traffic at both the social and individual levels.},
  booktitle   = {Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems},
  pages       = {2571–2573},
  numpages    = {3},
  keywords    = {autonomous driving, monte-carlo tree search, trajectory generation, vehicle flow},
  location    = {London, United Kingdom},
  series      = {AAMAS '23},
  abbr        = {AAMAS},
  arxiv       = {2302.06803},
  bibtex_show = {true},
  selected    = {true}
}

@article{10.1016/j.robot.2021.103997,
  title       = {CL-MAPF: Multi-Agent Path Finding for Car-Like robots with kinematic and spatiotemporal constraints},
  journal     = {Robotics and Autonomous Systems},
  volume      = {150},
  pages       = {103997},
  year        = {2022},
  issn        = {0921-8890},
  doi         = {https://doi.org/10.1016/j.robot.2021.103997},
  url         = {https://www.sciencedirect.com/science/article/pii/S0921889021002530},
  author      = {Licheng Wen and Yong Liu and Hongliang Li},
  keywords    = {Multi-agent systems, Path planning, Mobile robots},
  abstract    = {Multi-Agent Path Finding has been widely studied in the past few years due to its broad application in the field of robotics and AI. However, previous solvers rely on several simplifying assumptions. This limits their applicability in numerous real-world domains that adopt nonholonomic car-like agents rather than holonomic ones. In this paper, we give a mathematical formalization of the Multi-Agent Path Finding for Car-Like robots (CL-MAPF) problem. We propose a novel hierarchical search-based solver called Car-Like Conflict-Based Search to address this problem. It applies a body conflict tree to address collisions considering the shapes of the agents. We introduce a new algorithm called Spatiotemporal Hybrid-State A* as the single-agent planner to generate agents’ paths satisfying both kinematic and spatiotemporal constraints. We also present a sequential planning version of our method, sacrificing a small amount of solution quality to achieve a significant reduction in runtime. We compare our method with two baseline algorithms on a dedicated benchmark and validate it in real-world scenarios. The experiment results show that the planning success rate of both baseline algorithms is below 50\% for all six scenarios, while our algorithm maintains that of over 98\%. It also gives clear evidence that our algorithm scales well to 100 agents in 300 m × 300 m scenario and is able to produce solutions that can be directly applied to Ackermann-steering robots in the real world. The benchmark and source code are released in https://github.com/APRIL-ZJU/CL-CBS. The video of the experiments can be found on YouTube.},
  preview     = {clcbs.gif},
  abbr        = {RAS},
  arxiv       = {2011.00441},
  code        = {https://github.com/APRIL-ZJU/CL-CBS},
  video       = {https://www.youtube.com/watch?v=KThsX04ABvc},
  bibtex_show = {true},
  selected    = {true}
}

@inproceedings{10.1109/AIM43001.2020.9158907,
  author      = {Wen, Licheng and Yan, Jiaqing and Yang, Xuemeng and Liu, Yong and Gu, Yong},
  title       = {Collision-Free Trajectory Planning for Autonomous Surface Vehicle},
  year        = {2020},
  publisher   = {IEEE Press},
  url         = {https://doi.org/10.1109/AIM43001.2020.9158907},
  doi         = {10.1109/AIM43001.2020.9158907},
  abstract    = {In this paper, we propose an efficient and accurate method for autonomous surface vehicles to generate a smooth and collision-free trajectory considering its dynamics constraints. We decouple the trajectory planning problem as a front-end feasible path searching and a back-end kinodynamic trajectory optimization. Firstly, we model the type of two-thrusts under-actuated surface vessel. Then we adopt a sampling-based path searching to find an asymptotic optimal path through the obstacle-surrounding environment and extract several waypoints from it. We apply a numerical optimization method in the back-end to generate the trajectory. From the perspective of security in the field voyage, we propose the sailing corridor method to guarantee the trajectory away from obstacles. Moreover, considering limited fuel ASV carrying, we design a numerical objective function which can optimize a fuel-saving trajectory. Finally, we validate and compare the proposed method in simulation environments and the results fit our expected trajectory.},
  booktitle   = {2020 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM)},
  pages       = {1098–1105},
  numpages    = {8},
  location    = {Boston, MA, USA},
  abbr        = {AIM},
  arxiv       = {2005.09857},
  bibtex_show = {true},
  html        = {https://www.youtube.com/embed/7Yt-nmpmQFE},
  selected    = {false}
}
}

@article{10.1016/j.ins.2023.119085,
  title       = {Decomposing shared networks for separate cooperation with multi-agent reinforcement learning},
  journal     = {Information Sciences},
  volume      = {641},
  pages       = {119085},
  year        = {2023},
  issn        = {0020-0255},
  doi         = {https://doi.org/10.1016/j.ins.2023.119085},
  url         = {https://www.sciencedirect.com/science/article/pii/S0020025523006709},
  author      = {Weiwei Liu and Linpeng Peng and Licheng Wen and Jian Yang and Yong Liu},
  keywords    = {Multi-agent reinforcement learning, Neural network, Multi-agent systems, Navigation planning},
  abstract    = {Sharing network parameters between agents is an essential and typical operation to improve the scalability of multi-agent reinforcement learning algorithms. However, agents with different tasks sharing the same network parameters are not conducive to distinguishing the agents' skills. In addition, the importance of communication between agents undertaking the same task is much higher than that with external agents. Therefore, we propose Dual Cooperation Networks (DCN). In order to distinguish whether agents undertake the same task, all agents are grouped according to their status through the graph neural network instead of the traditional proximity. The agent communicates within the group to achieve strong cooperation. After that, the global value function is decomposed by groups to facilitate cooperation between groups. Finally, we have verified it in simulation and physical hardware, and the algorithm has achieved excellent performance.},
  bibtex_show = {true},
  abbr        = {J. Inf. Sci.},
  selected    = {false}
}

@inproceedings{10.1109/IROS51168.2021.9636224,
  author      = {Liu, Shanqi and Wen, Licheng and Cui, Jinhao and Yang, Xuemeng and Cao, Junjie and Liu, Yong},
  title       = {Moving Forward in Formation: A Decentralized Hierarchical Learning Approach to Multi-Agent Moving Together},
  year        = {2021},
  publisher   = {IEEE Press},
  url         = {https://doi.org/10.1109/IROS51168.2021.9636224},
  doi         = {10.1109/IROS51168.2021.9636224},
  abstract    = {Multi-agent path finding in formation has many potential real-world applications like mobile warehouse robotics. However, previous multi-agent path finding (MAPF) methods hardly take formation into consideration. Further-more, they are usually centralized planners and require the whole state of the environment. Other decentralized partially observable approaches to MAPF are reinforcement learning (RL) methods. However, these RL methods encounter difficulties when learning path finding and formation problems at the same time. In this paper, we propose a novel decentralized partially observable RL algorithm that uses a hierarchical structure to decompose the multi-objective task into unrelated ones. It also calculates a theoretical weight that makes each tasks reward has equal influence on the final RL value function. Additionally, we introduce a communication method that helps agents cooperate with each other. Experiments in simulation show that our method outperforms other end-to-end RL methods and our method can naturally scale to large world sizes where centralized planner struggles. We also deploy and validate our method in a real-world scenario.},
  booktitle   = {2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages       = {4777–4784},
  numpages    = {8},
  location    = {Prague, Czech Republic},
  abbr        = {IROS},
  arxiv       = {2011.02373},
  bibtex_show = {true},
  selected    = {false}
}

@inproceedings{10.1007/978-3-030-27544-0_33,
  author      = {Huang, Zheyuan and Chen, Lingyun and Li, Jiacheng and Wang, Yunkai and Chen, Zexi and Wen, Licheng and Gu, Jianyang and Hu, Peng and Xiong, Rong},
  title       = {RoboCup SSL 2018 Champion Team Paper},
  year        = {2018},
  isbn        = {978-3-030-27543-3},
  publisher   = {Springer-Verlag},
  address     = {Berlin, Heidelberg},
  url         = {https://doi.org/10.1007/978-3-030-27544-0_33},
  doi         = {10.1007/978-3-030-27544-0_33},
  abstract    = {The Small Size League is one of the important events in RoboCup Soccer. ZJUNlict got the first place in RoboCup 2018. In this paper, we introduce the new innovations and development we have made in the past year. These innovations include the mechanical part which accounted for most of our incredible goals and software part which enables us to play the game under a terrible vision situation. We also purpose an interception prediction algorithm to achieve some skills and improve our ball possession rate.},
  booktitle   = {RoboCup 2018: Robot World Cup XXII},
  pages       = {401–412},
  numpages    = {12},
  keywords    = {RoboCup, Vision prediction, Dribbler, Interception prediction},
  location    = {Montr\'{e}al, QC, Canada},
  abbr        = {RoboCup},
  bibtex_show = {true},
  selected    = {false}
}

@inproceedings{10.1007/978-3-030-35699-6_39,
  author      = {Chen, Zexi
                 and Zhang, Haodong
                 and Guo, Dashun
                 and Jia, Shenhan
                 and Fang, Xianze
                 and Huang, Zheyuan
                 and Wang, Yunkai
                 and Hu, Peng
                 and Wen, Licheng
                 and Chen, Lingyun
                 and Li, Zhengxi
                 and Xiong, Rong},
  editor      = {Chalup, Stephan
                 and Niemueller, Tim
                 and Suthakorn, Jackrit
                 and Williams, Mary-Anne},
  title       = {Champion Team Paper: Dynamic Passing-Shooting Algorithm of the RoboCup Soccer SSL 2019 Champion},
  booktitle   = {RoboCup 2019: Robot World Cup XXIII},
  year        = {2019},
  publisher   = {Springer International Publishing},
  address     = {Cham},
  pages       = {479--490},
  abstract    = {ZJUNlict became the Small Size League Champion of RoboCup 2019 with 6 victories and 1 tie for their 7 games. The overwhelming ability of ball-handling and passing allows ZJUNlict to greatly threaten its opponent and almost kept its goal clear without being threatened. This paper presents the core technology of its ball-handling and robot movement which consist of hardware optimization, dynamic passing and shooting strategy, and multi-agent cooperation and formation. We first describe the mechanical optimization on the placement of the capacitors, the redesign of the damping system of the dribbler and the electrical optimization on the replacement of the core chip. We then describe our passing point algorithm. The passing and shooting strategy can be separated into two different parts, where we search the passing point on SBIP-DPPS and evaluate the point based on the ball model. The statements and the conclusion should be supported by the performances and log of games on Small Size League RoboCup 2019.},
  isbn        = {978-3-030-35699-6},
  abbr        = {RoboCup},
  arxiv       = {1909.07717},
  bibtex_show = {true},
  selected    = {false}
}

